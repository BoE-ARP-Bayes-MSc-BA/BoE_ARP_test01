{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2e4d73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T11:09:54.100806Z",
     "start_time": "2022-07-11T11:09:53.641418Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b7ec4",
   "metadata": {},
   "source": [
    "### Define function for \"Cleaning\" and \"participants list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddad1f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T11:12:18.982048Z",
     "start_time": "2022-07-11T11:12:18.949615Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_text(contents):\n",
    "    ### Cleaning all the unwanted rows in the transcript\n",
    "    df = pd.DataFrame(contents)\n",
    "\n",
    "    # remove the unnessary string\n",
    "    df[0] = df[0].str.replace('\\n','')\n",
    "    df[0] = df[0].str.replace('Bloomberg Transcript','')\n",
    "    df[0] = df[0].str.replace('\\x0c\\n','')\n",
    "    df[0] = df[0].str.replace('FINAL','')\n",
    "    df[0] = df[0].str.replace('A - ','')\n",
    "    df[0] = df[0].str.replace('Q - ','')\n",
    "\n",
    "    # using re to remove the unnessary string\n",
    "    def drop_unnessary(x):\n",
    "        page = re.findall(r'Page \\d+ of \\d+', x) # 'page ... of ... '\n",
    "        BIO = re.findall(r'{BIO', x) # '{BIO 18731996 <GO>}'\n",
    "        Company_Name = re.findall(r'Company N ame:', x) # 'Company N ame: H annover Rueck SE'\n",
    "        Company_Ticker = re.findall(r'Company Ticker:', x) # 'Company Ticker: H N R1 GR Equity'\n",
    "        Date = re.findall(r'Date:', x) # Date: 2015-03-10\n",
    "        if page == [] and BIO == [] and Company_Name == [] and Company_Ticker == [] and Date == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_unnessary(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the final page declaration\n",
    "    df = df[df[0] != 'This transcript may not be 100 percent accurate and may contain misspellings and other']\n",
    "    df = df[df[0] != 'inaccuracies. This transcript is provided \"as is\", without express or implied warranties of']\n",
    "    df = df[df[0] != 'any kind. Bloomberg retains all rights to this transcript and provides it solely for your']\n",
    "    df = df[df[0] != 'personal, non-commercial use. Bloomberg, its suppliers and third-party agents shall']\n",
    "    df = df[df[0] != 'have no liability for errors in this transcript or for lost profits, losses, or direct, indirect,']\n",
    "    df = df[df[0] != 'incidental, consequential, special or punitive damages in connection with the']\n",
    "    df = df[df[0] != 'furnishing, performance or use of such transcript. Neither the information nor any']\n",
    "    df = df[df[0] != 'opinion expressed in this transcript constitutes a solicitation of the purchase or sale of']\n",
    "    df = df[df[0] != 'securities or commodities. Any opinion expressed in the transcript does not necessarily']\n",
    "    # df = df[df[0] != 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights']  \n",
    "    df = df[df[0] != 'reserved. Any reproduction, redistribution or retransmission is expressly prohibited.']\n",
    "    # ¬© could not be identified, would apply re\n",
    "    \n",
    "    def drop_Bloomberg_mark(x):\n",
    "        Bloomberg_mark = re.findall(r'reflect the views of Bloomberg LP', x) # 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights'\n",
    "        if Bloomberg_mark == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_Bloomberg_mark(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the empthy row\n",
    "    df = df[df[0] != '']\n",
    "    df = df[df[0] != '\f",
    "']\n",
    "\n",
    "    return df\n",
    "\n",
    "def participants_list(df):\n",
    "    # reset the index to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #  'Company Participants' index\n",
    "    # df.loc[df[0] == 'Company Participants']\n",
    "    Participant_start_index = df.index[df.iloc[:,0] == 'Company Participants'].tolist()\n",
    "    #  'Other Participants' index\n",
    "    # df.loc[df[0] == 'Other Participants']\n",
    "    Participant_middle_index = df.index[df.iloc[:,0] == 'Other Participants'].tolist()\n",
    "    #  'MANAGEMENT DISCUSSION SECTION' index, is the beginning of the management discussion, would stop before this row\n",
    "    # df.loc[df[0] == 'MANAGEMENT DISCUSSION SECTION']\n",
    "    Participant_end_index = df.index[df.iloc[:,0] == 'MANAGEMENT DISCUSSION SECTION' ].tolist()\n",
    "    # try to find the 'MANAGEMENT DISCUSSION SECTION' or 'Presentation' index\n",
    "    if Participant_end_index == []:\n",
    "        Participant_end_index = df.index[df.iloc[:,0] == 'Presentation'].tolist()\n",
    "\n",
    "    #print(Participant_start_index, Participant_middle_index, Participant_end_index)\n",
    "\n",
    "    # make the list of company_paticipants and other_participants\n",
    "    company_paticipants = df.loc[Participant_start_index[0]+1:Participant_middle_index[0]-1]\n",
    "    company_paticipants.drop(company_paticipants.index[company_paticipants.iloc[:,0] == ''].tolist(), inplace=True)\n",
    "    company_paticipants = company_paticipants.values.tolist()\n",
    "\n",
    "    other_paticipants = df.loc[Participant_middle_index[0]+1:Participant_end_index[0]-1]\n",
    "    other_paticipants.drop(other_paticipants.index[other_paticipants.iloc[:,0] == ''].tolist(), inplace=True)\n",
    "    other_paticipants = other_paticipants.values.tolist()\n",
    "\n",
    "    # print(\"==========================\")\n",
    "    # print(\"the company paticipants is: \", company_paticipants)\n",
    "    # print(\"==========================\")\n",
    "    # print(\"the other paticipants is: \", other_paticipants)\n",
    "\n",
    "    #%%\n",
    "    # after extract the paticipants, we can drop those information to make the transcript more clear\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(range(df.index[df.iloc[:,0] == 'Company Participants'].tolist()[0],df.index[df.iloc[:,0].isin(['MANAGEMENT DISCUSSION SECTION','Presentation'])].tolist()[0]+1))\n",
    "\n",
    "    # drop the first row of the df\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.iloc[1: , :]\n",
    "\n",
    "\n",
    "    # reset the index again to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "    # # save to csv\n",
    "    # df.to_csv('/Users/timliu/Desktop/output/df.csv')\n",
    "    return df, company_paticipants, other_paticipants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abfa1a",
   "metadata": {},
   "source": [
    "### Testing on the single company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d802c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T12:07:32.684384Z",
     "start_time": "2022-07-11T12:07:29.426610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hienanh/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "poppler error creating document",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yp/gsl3sklx6bg6x689_qhhd7300000gn/T/ipykernel_9866/894171469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Load PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdftotext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Save all text to a txt file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: poppler error creating document"
     ]
    }
   ],
   "source": [
    "path = \"/Users/hienanh/Documents/GitHub/final_01/Transcript\"#/European (Re)Insurers/HNR1 GY\" \n",
    "save_path = \"/Users/hienanh/Documents/GitHub/final_01/Output\"\n",
    "\n",
    "# all files path\n",
    "company_paths = []\n",
    "sectors = os.listdir(path) \n",
    "for sector in sectors:\n",
    "    # path to each sector files\n",
    "    if sector != '.DS_Store':\n",
    "        sector_path = path+\"/\"+sector\n",
    "    \n",
    "    # path to each company files\n",
    "    companies = os.listdir(sector_path) \n",
    "    for company in companies:\n",
    "        if company != '.DS_Store':\n",
    "            company_path = sector_path+\"/\"+company\n",
    "            company_paths.append(company_path)\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame()\n",
    "df_clean_na = pd.DataFrame(np.zeros((2500,1)), columns=['index']) # create a dataframe with 2500 rows\n",
    "all_participants = []            \n",
    "\n",
    "for single_path in company_paths:\n",
    "    files = os.listdir(single_path)\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            # print(file)\n",
    "            # Load PDF\n",
    "            with open(single_path+\"/\"+file, \"rb\") as f:\n",
    "                pdf = pdftotext.PDF(f)\n",
    "            # Save all text to a txt file.\n",
    "            with open(save_path+\"/\"+file.replace(\".pdf\", \".txt\"), \"w\") as f:\n",
    "                f.write(\"\\n\\n\".join(pdf))\n",
    "            # open the text file\n",
    "            with open(save_path+\"/\"+file.replace(\".pdf\", \".txt\")) as f:\n",
    "                contents = f.readlines()\n",
    "                df_clean = cleaning_text(contents)\n",
    "                # extract all the participants\n",
    "                df_pure_text,company_paticipants,other_paticipants = participants_list(df_clean)\n",
    "                all_participants.append(company_paticipants)\n",
    "                all_participants.append(other_paticipants)\n",
    "                # using the file name to set as the dataframe's column name\n",
    "                # df[f\"{files.index(file)}\"] = df_clean\n",
    "                df[f\"{files[files.index(file)]}\"] = df_pure_text\n",
    "                df_clean_na[f\"{files[files.index(file)]}\"] = df[f\"{files[files.index(file)]}\"].dropna(inplace=False).reset_index(drop=True)\n",
    "\n",
    "# drop the first column of the df\n",
    "df_clean_na = df_clean_na.iloc[:,1:]\n",
    "df_clean_na.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
