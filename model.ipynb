{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_tokenizers_available' from 'transformers.utils' (/Users/user/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1874ec925f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# import nlpaug.augmenter.sentence as nas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_tokenizers_available' from 'transformers.utils' (/Users/user/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset # 可以繼承 類似map and unmap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import BertTokenizer,BertModel,get_linear_schedule_with_warmup \n",
    "import seaborn as sns\n",
    "# import nlpaug.augmenter.sentence as nas\n",
    "# import nlpaug.augmenter.char as nac\n",
    "# import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the package version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>meeting_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>749</td>\n",
       "      <td>Ladies and gentlemen. Good afternoon. Welcome,...</td>\n",
       "      <td>20190424_AXA_SA-_Shareholder_Mtg_Call_2019-4-2...</td>\n",
       "      <td>2019-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1492</td>\n",
       "      <td>Greetings. Welcome to the Markel Corporation F...</td>\n",
       "      <td>20120510_Markel_Corp-_Earnings_Call_2012-5-10_...</td>\n",
       "      <td>2012-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>446</td>\n",
       "      <td>Good morning or good afternoon. Welcome to Swi...</td>\n",
       "      <td>20190731_Swiss_Re_AG-_Earnings_Call_2019-7-31_...</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1438</td>\n",
       "      <td>Market Cap: 69,035.17. Current PX: 148.33. YTD...</td>\n",
       "      <td>20170726_Chubb_Ltd-_Earnings_Call_2017-7-26_FS...</td>\n",
       "      <td>2017-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337</td>\n",
       "      <td>Yasuyoshi Karasawa. Good afternoon, ladies and...</td>\n",
       "      <td>20190524_MS-AD_INSURANCE-_Guidance_Call_2019-5...</td>\n",
       "      <td>2019-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>423</td>\n",
       "      <td>Ladies and gentlemen, good morning or good aft...</td>\n",
       "      <td>20160429_Swiss_Re_AG-_Earnings_Call_2016-4-29_...</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>96</td>\n",
       "      <td>Welcome, everyone, to our presentation today. ...</td>\n",
       "      <td>20200526_Aviva_PLC-_Shareholder_Mtg_Call_2020-...</td>\n",
       "      <td>2020-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>40</td>\n",
       "      <td>Operator. (Operator Instructions) Good day, la...</td>\n",
       "      <td>20191204_Sanlam_Ltd-_Sales_Results_Call_2019-1...</td>\n",
       "      <td>2019-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>605</td>\n",
       "      <td>Greetings, and welcome to the Lancashire Holdi...</td>\n",
       "      <td>20150729_LANCASHIRE_HOLDI-_Earnings_Call_2015-...</td>\n",
       "      <td>2015-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1115</td>\n",
       "      <td>Operator. Good day, and welcome to the Gjensid...</td>\n",
       "      <td>20181025_GJENSIDIGE_FORSI-_Earnings_Call_2018-...</td>\n",
       "      <td>2018-10-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                       meeting_text  \\\n",
       "0           749  Ladies and gentlemen. Good afternoon. Welcome,...   \n",
       "1          1492  Greetings. Welcome to the Markel Corporation F...   \n",
       "2           446  Good morning or good afternoon. Welcome to Swi...   \n",
       "3          1438  Market Cap: 69,035.17. Current PX: 148.33. YTD...   \n",
       "4           337  Yasuyoshi Karasawa. Good afternoon, ladies and...   \n",
       "..          ...                                                ...   \n",
       "913         423  Ladies and gentlemen, good morning or good aft...   \n",
       "914          96  Welcome, everyone, to our presentation today. ...   \n",
       "915          40  Operator. (Operator Instructions) Good day, la...   \n",
       "916         605  Greetings, and welcome to the Lancashire Holdi...   \n",
       "917        1115  Operator. Good day, and welcome to the Gjensid...   \n",
       "\n",
       "                                             file_name        date  \n",
       "0    20190424_AXA_SA-_Shareholder_Mtg_Call_2019-4-2...  2019-04-24  \n",
       "1    20120510_Markel_Corp-_Earnings_Call_2012-5-10_...  2012-05-10  \n",
       "2    20190731_Swiss_Re_AG-_Earnings_Call_2019-7-31_...  2019-07-31  \n",
       "3    20170726_Chubb_Ltd-_Earnings_Call_2017-7-26_FS...  2017-07-26  \n",
       "4    20190524_MS-AD_INSURANCE-_Guidance_Call_2019-5...  2019-05-24  \n",
       "..                                                 ...         ...  \n",
       "913  20160429_Swiss_Re_AG-_Earnings_Call_2016-4-29_...  2016-04-29  \n",
       "914  20200526_Aviva_PLC-_Shareholder_Mtg_Call_2020-...  2020-05-26  \n",
       "915  20191204_Sanlam_Ltd-_Sales_Results_Call_2019-1...  2019-12-04  \n",
       "916  20150729_LANCASHIRE_HOLDI-_Earnings_Call_2015-...  2015-07-29  \n",
       "917  20181025_GJENSIDIGE_FORSI-_Earnings_Call_2018-...  2018-10-25  \n",
       "\n",
       "[918 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file\n",
    "df = pd.read_csv('df_sample.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleaning_text(contents):\n",
    "#     ### Cleaning all the unwanted rows in the transcript\n",
    "#     df = pd.DataFrame(contents)\n",
    "\n",
    "#     # remove the unnessary string\n",
    "#     df[0] = df[0].str.replace('\\n','')\n",
    "#     df[0] = df[0].str.replace('Bloomberg Transcript','')\n",
    "#     df[0] = df[0].str.replace('\\x0c\\n','')\n",
    "#     df[0] = df[0].str.replace('FINAL','')\n",
    "#     df[0] = df[0].str.replace('A - ','')\n",
    "#     df[0] = df[0].str.replace('Q - ','')\n",
    "\n",
    "#     # using re to remove the unnessary string\n",
    "#     def drop_unnessary(x):\n",
    "#         page = re.findall(r'Page \\d+ of \\d+', x) # 'page ... of ... '\n",
    "#         BIO = re.findall(r'{BIO', x) # '{BIO 18731996 <GO>}'\n",
    "#         Company_Name = re.findall(r'Company N ame:', x) # 'Company N ame: H annover Rueck SE'\n",
    "#         Company_Ticker = re.findall(r'Company Ticker:', x) # 'Company Ticker: H N R1 GR Equity'\n",
    "#         Date = re.findall(r'Date:', x) # Date: 2015-03-10\n",
    "#         if page == [] and BIO == [] and Company_Name == [] and Company_Ticker == [] and Date == []:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "\n",
    "#     true_false = df[0].apply(lambda x: drop_unnessary(x))\n",
    "#     df = df[true_false]\n",
    "\n",
    "#     # drop the final page declaration\n",
    "#     df = df[df[0] != 'This transcript may not be 100 percent accurate and may contain misspellings and other']\n",
    "#     df = df[df[0] != 'inaccuracies. This transcript is provided \"as is\", without express or implied warranties of']\n",
    "#     df = df[df[0] != 'any kind. Bloomberg retains all rights to this transcript and provides it solely for your']\n",
    "#     df = df[df[0] != 'personal, non-commercial use. Bloomberg, its suppliers and third-party agents shall']\n",
    "#     df = df[df[0] != 'have no liability for errors in this transcript or for lost profits, losses, or direct, indirect,']\n",
    "#     df = df[df[0] != 'incidental, consequential, special or punitive damages in connection with the']\n",
    "#     df = df[df[0] != 'furnishing, performance or use of such transcript. Neither the information nor any']\n",
    "#     df = df[df[0] != 'opinion expressed in this transcript constitutes a solicitation of the purchase or sale of']\n",
    "#     df = df[df[0] != 'securities or commodities. Any opinion expressed in the transcript does not necessarily']\n",
    "#     # df = df[df[0] != 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights']  \n",
    "#     df = df[df[0] != 'reserved. Any reproduction, redistribution or retransmission is expressly prohibited.']\n",
    "#     # ¬© could not be identified, would apply re\n",
    "#     def drop_Bloomberg_mark(x):\n",
    "#         Bloomberg_mark = re.findall(r'reflect the views of Bloomberg LP', x) # 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights'\n",
    "#         if Bloomberg_mark == []:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "\n",
    "#     true_false = df[0].apply(lambda x: drop_Bloomberg_mark(x))\n",
    "#     df = df[true_false]\n",
    "\n",
    "#     # drop the empthy row\n",
    "#     df = df[df[0] != '']\n",
    "#     df = df[df[0] != '\f']\n",
    "\n",
    "#     return df\n",
    "\n",
    "def preprocess(text):\n",
    "      pattern = re.compile(r'\\s+')\n",
    "  text=text.replace('\\u202f',' ').replace('xa0',' ')\n",
    "  text=re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "  text=re.sub(r\"\\\\u00b4\",r'',text)\n",
    "  text=re.sub(pattern, ' ', text)\n",
    "  text = text.replace('?', ' ? ').replace(')', ') ').strip()\n",
    "  return text\n",
    "\n",
    "  df['imdb_user_review']=df['imdb_user_review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f92f6acccaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meeting_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-76dcfe875243>\u001b[0m in \u001b[0;36mcleaning_text\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# remove the unnessary string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bloomberg Transcript'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\x0c\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "df_clean = cleaning_text(df['meeting_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "701d4f28dcd0866722f5108a3a4cbcd08882d26398b6d44117e791d7b8102912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
